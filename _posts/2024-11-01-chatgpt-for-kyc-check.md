---
layouts: post
title: ChatGPT für KYC-Checks? Bloß nicht!
description: KYC-Prüfungen sind ein wichtiger Bestandteil im Compliance-Bereich, aber ein LLM wie ChatGPT für diese Zwecke einzusetzen, ist nicht so einfach, wie es vielleicht scheint.
date: 2024-11-07 15:01:35 +0300
image: '/images/blog-chatgpt-kyc.jpg'
tags: [KYC, Compliance, LLM, Machine Learning]
---

## ChatGPT für KYC-Checks? Bloß nicht!

KYC (Know Your Customer)-Prüfungen sind für Unternehmen essenziell, um sicherzustellen, dass keine Geschäftsbeziehungen mit Personen oder Firmen bestehen, die auf Sanktions-, Terror- oder PEP-Listen (Politically Exposed Persons) stehen. Der erste Gedanke vieler Menschen ist, dass ein leistungsfähiges Sprachmodell wie ChatGPT diese Aufgabe effizient übernehmen könnte. Doch eine genauere Betrachtung zeigt, warum das aktuelle Potenzial von ChatGPT für KYC-Checks ungeeignet ist.

### Warum ChatGPT als KYC-Prüfer auf den ersten Blick überzeugt

Ein Large Language Model (LLM) wie ChatGPT bringt einige Fähigkeiten mit, die für KYC-Prüfungen theoretisch vorteilhaft erscheinen:

- **Interpretation von Personendaten:** ChatGPT ist ausgezeichnet darin, Namen, Geburtsdaten oder Herkunftsländer zu interpretieren. Diese Fähigkeit kann hilfreich sein, wenn es darum geht, Personen auf Listen wie der EU-Sanktionsliste oder der OFAC (Office of Foreign Assets Control) zu identifizieren.
- **Flexible Datenbasis:** In einem angepassten GPT-Model könnten theoretisch Prüflisten wie die EU- oder OFAC-Sanktionslisten hinterlegt werden, oder auch kommerzielle Datenquellen wie World-Check oder Dow Jones Factiva.
- **Unscharfes Matching:** Ein unscharfer Vergleich, bei dem geringfügige Abweichungen in Namen (etwa Buchstabendreher oder fehlende Sonderzeichen) erkannt werden, ist eine große Stärke von ChatGPT und wäre bei KYC-Checks hilfreich.

### Praxistest: Warum es nicht funktioniert

Ich habe selbst einen Test mit einer EU-Sanktionsliste und einer gefälschten Namensliste durchgeführt, die teilweise manipulierte Namen aus der Sanktionsliste enthielt. ChatGPT sollte erkennen, welche Namen mit denen auf der Liste übereinstimmen, auch wenn kleine Variationen vorhanden waren. Das Ergebnis war in vielerlei Hinsicht erstaunlich:

1. **Unerwartete Lösungsansätze:** Anstatt das Matching rein mit seinem LLM-Fähigkeiten durchzuführen, versuchte ChatGPT, das Problem durch ein Python-Script zu lösen. Das deutet darauf hin, dass das LLM selbst "einsieht", dass es für diese Aufgabe nicht ideal ist und versucht, den "falschen Weg" zu umgehen.

2. **Inkonsistente Ergebnisse:** Durch Änderungen in der Reihenfolge der Namen oder den bisherigen Trefferstatus wurden die Ergebnisse beeinflusst. Ein identischer Datensatz führte bei erneutem Testen zu teils unterschiedlichen Resultaten. Diese Inkonsistenz ist für KYC-Checks nicht akzeptabel, da hier Genauigkeit und Reproduzierbarkeit im Vordergrund stehen.

### Compliance-Anforderungen: Nachvollziehbarkeit und Dokumentation

Ein großes Problem bei der Nutzung von ChatGPT für KYC ist die fehlende **Nachvollziehbarkeit** der Entscheidungen. Regulatorische Anforderungen wie die der BaFin (Bundesanstalt für Finanzdienstleistungsaufsicht) schreiben vor, dass die Entscheidungswege bei Modellen in der Compliance nachvollziehbar sein müssen. Es gibt maschinelle Lernalgorithmen, die diese Nachvollziehbarkeit garantieren können, doch LLMs bieten dies derzeit nicht. Ein Modell, das Entscheidungen trifft, die nicht eindeutig dokumentiert und überprüfbar sind, wird niemals von Wirtschaftsprüfern oder der BaFin im Compliance-Umfeld akzeptiert werden.

### Fazit: Ein eigenes KYC-Modell ist der bessere Weg

Auch wenn die Idee, ChatGPT für KYC-Checks zu nutzen, verlockend ist, zeigt die Praxis, dass ein LLM für diesen Bereich nicht geeignet ist. Das LLM „weiß“ dies in gewisser Weise selbst, indem es versucht, den Prozess auf externe Python-Skripte auszulagern. Statt ein LLM zu nutzen, ist es ratsamer, sich mit der Materie vertraut zu machen und ein **nachvollziehbares, auf Machine Learning basiertes Modell** zu entwickeln. Nur so besteht eine Chance, im regulierten Finanzsektor zu bestehen und den Anforderungen gerecht zu werden.

Ein LLM wird in naher Zukunft wohl kaum die Anforderungen an einen stabilen, nachvollziehbaren KYC-Algorithmus erfüllen können. Daher ist es essenziell, sich auf bewährte Algorithmen und speziell trainierte Machine-Learning-Modelle zu stützen, die Compliance-Standards erfüllen und im Falle von Audits transparent und prüfbar sind.
